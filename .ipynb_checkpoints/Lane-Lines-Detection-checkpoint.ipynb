{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raja Faizan Nazir\n",
      "Python 3.9.7\n",
      "pip 21.3.1 from /home/raja-faizan-nazir/.local/lib/python3.9/site-packages/pip (python 3.9)\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!pip --version\n",
    "# Tested on Python 3.9.7\n",
    "# Tested on Pip 21.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: opencv-python\r\n",
      "Version: 4.5.5.62\r\n",
      "Summary: Wrapper package for OpenCV python bindings.\r\n",
      "Home-page: https://github.com/skvark/opencv-python\r\n",
      "Author: \r\n",
      "Author-email: \r\n",
      "License: MIT\r\n",
      "Location: /home/raja-faizan-nazir/.local/lib/python3.9/site-packages\r\n",
      "Requires: numpy, numpy, numpy\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip show opencv-python\n",
    "# Tested on Cv2 Version 4.5.5.62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_images(images, cols = 2, rows = 5, cmap=None):\n",
    "    \"\"\"\n",
    "    Display a list of images in a single figure with matplotlib.\n",
    "        Parameters:\n",
    "            images: List of np.arrays compatible with plt.imshow.\n",
    "            cols (Default = 2): Number of columns in the figure.\n",
    "            rows (Default = 5): Number of rows in the figure.\n",
    "            cmap (Default = None): Used to display gray images.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 11))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        #Use gray scale color map if there is only one channel\n",
    "        cmap = 'gray' if len(image.shape) == 2 else cmap\n",
    "        plt.imshow(image, cmap = cmap)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the test images\n",
    "test_images = [plt.imread(img) for img in glob.glob('test_images/*.jpg')]\n",
    "list_images(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original RGB color selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will apply color selection to the `test_images` in the original RGB format. We will try to retain as much of the lane lines as possible, while blacking out most of the other stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB_color_selection(image):\n",
    "    \"\"\"\n",
    "    Apply color selection to RGB images to blackout everything except for white and yellow lane lines.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    #White color mask\n",
    "    lower_threshold = np.uint8([200, 200, 200])\n",
    "    upper_threshold = np.uint8([255, 255, 255])\n",
    "    white_mask = cv2.inRange(image, lower_threshold, upper_threshold)\n",
    "    \n",
    "    #Yellow color mask\n",
    "    lower_threshold = np.uint8([175, 175,   0])\n",
    "    upper_threshold = np.uint8([255, 255, 255])\n",
    "    yellow_mask = cv2.inRange(image, lower_threshold, upper_threshold)\n",
    "    \n",
    "    #Combine white and yellow masks\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
    "    \n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying color selection to `test_images` in the RGB color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_images(list(map(RGB_color_selection, test_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) HSV color space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wikipedia**: HSV is an alternative representation of the RGB color model. The HSV representation models the way colors mix together, with the saturation dimension resembling various shades of brightly colored paint, and the value dimension resembling the mixture of those paints with varying amounts of black or white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hsv(image):\n",
    "    \"\"\"\n",
    "    Convert RGB images to HSV.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "list_images(list(map(convert_hsv, test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HSV_color_selection(image):\n",
    "    \"\"\"\n",
    "    Apply color selection to the HSV images to blackout everything except for white and yellow lane lines.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    #Convert the input image to HSV\n",
    "    converted_image = convert_hsv(image)\n",
    "    \n",
    "    #White color mask\n",
    "    lower_threshold = np.uint8([0, 0, 210])\n",
    "    upper_threshold = np.uint8([255, 30, 255])\n",
    "    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
    "    \n",
    "    #Yellow color mask\n",
    "    lower_threshold = np.uint8([18, 80, 80])\n",
    "    upper_threshold = np.uint8([30, 255, 255])\n",
    "    yellow_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
    "    \n",
    "    #Combine white and yellow masks\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
    "    \n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying color selection to `test_images` in the HSV color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_images(list(map(HSV_color_selection, test_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) HSL color space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wikipedia**: HSL is an alternative representation of the RGB color model. The HSL model attempts to resemble more perceptual color models such as NCS or Munsell, placing fully saturated colors around a circle at a lightness value of 1/2, where a lightness value of 0 or 1 is fully black or white, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hsl(image):\n",
    "    \"\"\"\n",
    "    Convert RGB images to HSL.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "list_images(list(map(convert_hsl, test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HSL_color_selection(image):\n",
    "    \"\"\"\n",
    "    Apply color selection to the HSL images to blackout everything except for white and yellow lane lines.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    #Convert the input image to HSL\n",
    "    converted_image = convert_hsl(image)\n",
    "    \n",
    "    #White color mask\n",
    "    lower_threshold = np.uint8([0, 200, 0])\n",
    "    upper_threshold = np.uint8([255, 255, 255])\n",
    "    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
    "    \n",
    "    #Yellow color mask\n",
    "    lower_threshold = np.uint8([10, 0, 100])\n",
    "    upper_threshold = np.uint8([40, 255, 255])\n",
    "    yellow_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
    "    \n",
    "    #Combine white and yellow masks\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
    "    \n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying color selection to `test_images` in the HSL color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_images(list(map(HSL_color_selection, test_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using HSL produces the clearest lane lines of all color spaces. We will use them for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_selected_images = list(map(HSL_color_selection, test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Gray scaling the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Canny edge detection algorithm measures the intensity gradients of each pixel. So, we need to convert the images into gray scale in order to detect edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_scale(image):\n",
    "    \"\"\"\n",
    "    Convert images to gray scale.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_images = list(map(gray_scale, color_selected_images))\n",
    "list_images(gray_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Applying Gaussian smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wikipedia**: Since all edge detection results are easily affected by image noise, it is essential to filter out the noise to prevent false detection caused by noise. To smooth the image, a Gaussian filter is applied to convolve with the image. This step will slightly smooth the image to reduce the effects of obvious noise on the edge detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_smoothing(image, kernel_size = 13):\n",
    "    \"\"\"\n",
    "    Apply Gaussian filter to the input image.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "            kernel_size (Default = 13): The size of the Gaussian kernel will affect the performance of the detector.\n",
    "            It must be an odd number (3, 5, 7, ...).\n",
    "    \"\"\"\n",
    "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_images = list(map(gaussian_smoothing, gray_images))\n",
    "list_images(blur_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Applying Canny Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wikipedia**:\n",
    "The Process of Canny edge detection algorithm can be broken down to 5 different steps:\n",
    "1. Find the intensity gradients of the image\n",
    "2. Apply non-maximum suppression to get rid of spurious response to edge detection.\n",
    "3. Apply *double threshold* to determine potential edges.\n",
    "4. Track edge by hysteresis: Finalize the detection of edges by suppressing all the other edges that are weak and not connected to strong edges.\n",
    "\n",
    "**If an edge pixel’s gradient value is higher than the high threshold value, it is marked as a strong edge pixel. If an edge pixel’s gradient value is smaller than the high threshold value and larger than the low threshold value, it is marked as a weak edge pixel. If an edge pixel's value is smaller than the low threshold value, it will be suppressed.\n",
    "The two threshold values are empirically determined and their definition will depend on the content of a given input image.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_detector(image, low_threshold = 50, high_threshold = 150):\n",
    "    \"\"\"\n",
    "    Apply Canny Edge Detection algorithm to the input image.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "            low_threshold (Default = 50).\n",
    "            high_threshold (Default = 150).\n",
    "    \"\"\"\n",
    "    return cv2.Canny(image, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_detected_images = list(map(canny_detector, blur_images))\n",
    "list_images(edge_detected_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Region of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're interested in the area facing the camera, where the lane lines are found. So, we'll apply region masking to cut out everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_selection(image):\n",
    "    \"\"\"\n",
    "    Determine and cut the region of interest in the input image.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(image)   \n",
    "    #Defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(image.shape) > 2:\n",
    "        channel_count = image.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    #We could have used fixed numbers as the vertices of the polygon,\n",
    "    #but they will not be applicable to images with different dimesnions.\n",
    "    rows, cols = image.shape[:2]\n",
    "    bottom_left  = [cols * 0.1, rows * 0.95]\n",
    "    top_left     = [cols * 0.4, rows * 0.6]\n",
    "    bottom_right = [cols * 0.9, rows * 0.95]\n",
    "    top_right    = [cols * 0.6, rows * 0.6]\n",
    "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image = list(map(region_selection, edge_detected_images))\n",
    "list_images(masked_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hough Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hough transform is a technique which can be used to isolate features of a particular shape within an image. I'll use it to detected the lane lines in `selected_region_images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_transform(image):\n",
    "    \"\"\"\n",
    "    Determine and cut the region of interest in the input image.\n",
    "        Parameters:\n",
    "            image: The output of a Canny transform.\n",
    "    \"\"\"\n",
    "    rho = 1              #Distance resolution of the accumulator in pixels.\n",
    "    theta = np.pi/180    #Angle resolution of the accumulator in radians.\n",
    "    threshold = 20       #Only lines that are greater than threshold will be returned.\n",
    "    minLineLength = 20   #Line segments shorter than that are rejected.\n",
    "    maxLineGap = 300     #Maximum allowed gap between points on the same line to link them\n",
    "    return cv2.HoughLinesP(image, rho = rho, theta = theta, threshold = threshold,\n",
    "                           minLineLength = minLineLength, maxLineGap = maxLineGap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hough_lines` contains the list of lines detected in the selected region. Now, we will draw these detected lines onto the original `test_images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hough_lines = list(map(hough_transform, masked_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(image, lines, color = [255, 0, 0], thickness = 2):\n",
    "    \"\"\"\n",
    "    Draw lines onto the input image.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "            lines: The lines we want to draw.\n",
    "            color (Default = red): Line color.\n",
    "            thickness (Default = 2): Line thickness.\n",
    "    \"\"\"\n",
    "    image = np.copy(image)\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(image, (x1, y1), (x2, y2), color, thickness)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_images = []\n",
    "for image, lines in zip(test_images, hough_lines):\n",
    "    line_images.append(draw_lines(image, lines))\n",
    "    \n",
    "list_images(line_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Averaging and extrapolating the lane lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have multiple lines detected for each lane line. We need to average all these lines and draw a single line for each lane line.\n",
    "We also need to extrapolate the lane lines to cover the full lane line length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_slope_intercept(lines):\n",
    "    \"\"\"\n",
    "    Find the slope and intercept of the left and right lanes of each image.\n",
    "        Parameters:\n",
    "            lines: The output lines from Hough Transform.\n",
    "    \"\"\"\n",
    "    left_lines    = [] #(slope, intercept)\n",
    "    left_weights  = [] #(length,)\n",
    "    right_lines   = [] #(slope, intercept)\n",
    "    right_weights = [] #(length,)\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            if x1 == x2:\n",
    "                continue\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            intercept = y1 - (slope * x1)\n",
    "            length = np.sqrt(((y2 - y1) ** 2) + ((x2 - x1) ** 2))\n",
    "            if slope < 0:\n",
    "                left_lines.append((slope, intercept))\n",
    "                left_weights.append((length))\n",
    "            else:\n",
    "                right_lines.append((slope, intercept))\n",
    "                right_weights.append((length))\n",
    "    left_lane  = np.dot(left_weights,  left_lines) / np.sum(left_weights)  if len(left_weights) > 0 else None\n",
    "    right_lane = np.dot(right_weights, right_lines) / np.sum(right_weights) if len(right_weights) > 0 else None\n",
    "    return left_lane, right_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_points(y1, y2, line):\n",
    "    \"\"\"\n",
    "    Converts the slope and intercept of each line into pixel points.\n",
    "        Parameters:\n",
    "            y1: y-value of the line's starting point.\n",
    "            y2: y-value of the line's end point.\n",
    "            line: The slope and intercept of the line.\n",
    "    \"\"\"\n",
    "    if line is None:\n",
    "        return None\n",
    "    slope, intercept = line\n",
    "    x1 = int((y1 - intercept)/slope)\n",
    "    x2 = int((y2 - intercept)/slope)\n",
    "    y1 = int(y1)\n",
    "    y2 = int(y2)\n",
    "    return ((x1, y1), (x2, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_lines(image, lines):\n",
    "    \"\"\"\n",
    "    Create full lenght lines from pixel points.\n",
    "        Parameters:\n",
    "            image: The input test image.\n",
    "            lines: The output lines from Hough Transform.\n",
    "    \"\"\"\n",
    "    left_lane, right_lane = average_slope_intercept(lines)\n",
    "    y1 = image.shape[0]\n",
    "    y2 = y1 * 0.6\n",
    "    left_line  = pixel_points(y1, y2, left_lane)\n",
    "    right_line = pixel_points(y1, y2, right_lane)\n",
    "    return left_line, right_line\n",
    "\n",
    "    \n",
    "def draw_lane_lines(image, lines, color=[255, 0, 0], thickness=12):\n",
    "    \"\"\"\n",
    "    Draw lines onto the input image.\n",
    "        Parameters:\n",
    "            image: The input test image.\n",
    "            lines: The output lines from Hough Transform.\n",
    "            color (Default = red): Line color.\n",
    "            thickness (Default = 12): Line thickness. \n",
    "    \"\"\"\n",
    "    line_image = np.zeros_like(image)\n",
    "    for line in lines:\n",
    "        if line is not None:\n",
    "            cv2.line(line_image, *line,  color, thickness)\n",
    "    return cv2.addWeighted(image, 1.0, line_image, 1.0, 0.0)\n",
    "             \n",
    "    \n",
    "lane_images = []\n",
    "for image, lines in zip(test_images, hough_lines):\n",
    "    lane_images.append(draw_lane_lines(image, lane_lines(image, lines)))\n",
    "\n",
    "    \n",
    "list_images(lane_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply on video streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use the above functions to detect lane lines from a video stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import everything needed to edit/save/watch video clips\n",
    "from moviepy import *\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_processor(image):\n",
    "    \"\"\"\n",
    "    Process the input frame to detect lane lines.\n",
    "        Parameters:\n",
    "            image: Single video frame.\n",
    "    \"\"\"\n",
    "    color_select = HSL_color_selection(image)\n",
    "    gray         = gray_scale(color_select)\n",
    "    smooth       = gaussian_smoothing(gray)\n",
    "    edges        = canny_detector(smooth)\n",
    "    region       = region_selection(edges)\n",
    "    hough        = hough_transform(region)\n",
    "    result       = draw_lane_lines(image, lane_lines(image, hough))\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(test_video, output_video):\n",
    "    \"\"\"\n",
    "    Read input video stream and produce a video file with detected lane lines.\n",
    "        Parameters:\n",
    "            test_video: Input video.\n",
    "            output_video: A video file with detected lane lines.\n",
    "    \"\"\"\n",
    "    input_video = VideoFileClip(os.path.join('test_videos', test_video), audio=False)\n",
    "    processed = input_video.fl_image(frame_processor)\n",
    "    processed.write_videofile(os.path.join('output_videos', output_video), audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time process_video('solidWhiteRight.mp4', 'solidWhiteRight_output.mp4')\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\"output_videos\\solidWhiteRight_output.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time process_video('solidYellowLeft.mp4', 'solidYellowLeft_output.mp4')\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\"output_videos\\solidYellowLeft_output.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time process_video('challenge.mp4', 'challenge_output.mp4')\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\"output_videos\\challenge_output.mp4\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
